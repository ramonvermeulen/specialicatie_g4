{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data science Specialisatie Opdracht\n",
    "#### Uitgevoerd door Groep 4 bestaande uit: Ramon Vermeulen, Ruud van Rooijen, Nico Tammer en Thomas Lem\n",
    "Voor de opdracht hebben wij gekozen om niet mee te doen aan de NEC, maar een dataset van Kaggle te pakken. Deze is als volgt: https://www.kaggle.com/c/digit-recognizer.\n",
    "Met deze dataset willen wij 3 manieren van machinelearning vergelijken, en bepalen welke methode hiervoor het beste is met de kennis die wij gekregen hebben tijdens het vak van Data Science.\n",
    "\n",
    "De dataset waar wij mee aan de slag gaan is het MNIST (\"Modified National Institute of Standards and Technology\") dataset. De dataset betreft handgeschreven cijfers van 0-9 opgeslagen in 28x28 plaatjes. In de dataset is dit opgeslagen door per rij 784 kolommen te hebben waar per pixel de waarde opgeslagen word. Op deze manier kunnen wij in Python het plaate reconstrueren en analyseren, of puur op de data analyseren. \n",
    "\n",
    "Voor het vergelijken van verschillende methode hebben wij gekozen voor: k-Means, k-Nearest Neighbor en Tensor Flow. \n",
    "\n",
    "#### Dit notebook betreft TensorFlow.\n",
    "Om te zorgen dat je dit kan draaien tijdens het nakijken, zorg er voor dat je https://www.tensorflow.org/install/ TensorFlow hebt geinstalleerd. Voor Windows is het van belang dat je dan ook Python 3.5.2 draait in plaats van de 3.6 die anaconda standaard installeert. Anaconda bied hier in de command line wel downgrade functionaliteit voor.\n",
    "\n",
    "Dit kan door middel van het volgende commando: conda install python=3.5.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Voor tensorflow gebruiken we de ingebouwde dataset in tensorflow voor mnist. \n",
    "#### Is het zelfde als bij KNN en Kmeans maar makkelijker te importeren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-66683977dd0a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtutorials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MNIST_data/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model opzetten\n",
    "#### We maken een aantal variable aan die we later gebruiken bij het generegen van gewicht en het vooroordeel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "W = tf.Variable(tf.zeros([784, 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We kunnen nu ons model implementeren. Dit doen wij met de volgende regel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "#### We maken eerst een nieuwe placeholder aan, hier komen de correcte antwoorden in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_ = tf.placeholder(tf.float32, [None, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementeren van cross entropy en het instellen van de trainingsstapjes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nu starten we een InteractiveSession. (Deze worden gebruikt voor interactieve contexts, zoals bijvoorbeeld een shell) en maken we een operatie die zorgt dat dat onze variabele geinitialiseerd worden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nu willen we graag trainen. We runnen hem 1000 keer, en elke loop geven we hem random 1000 datapunten om te leren. Uiteraard zouden we graag alles willen gebruiken, maar helaas hebben we hier niet de processorkracht voor en is de winst in verhouding tot performance minimaal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for _ in range(2000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(1000)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Het resultaat\n",
    "#### We willen graag weten of het algoritme het goede getal heeft gevonden bij de data. hiervoor kijken we eerst naar het label wat het algoritme denkt dat het is, en vergelijken we die met het correcte label. Deze retourneert een lijst van booleans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nu casten we hem en bekijken we het resultaat, het blijkt dat nearest neighbors ongeveer even accuraat is als tensorflow. Wel hebben andere mensen accuracies tot wel 99% behaalt, echter hebben wij niet genoeg ervaring met Data Science om dit te reproduceren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(sess.run(accuracy, feed_dict={x:mnist.test.images, y_: mnist.test.labels}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
